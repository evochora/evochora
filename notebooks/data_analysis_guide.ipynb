{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "name": "Evochora Data Analysis Guide"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Evochora — Data Analysis Guide\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/evochora/evochora/blob/main/notebooks/data_analysis_guide.ipynb?flush_cache=true)\n\nThis notebook shows how to analyze [Evochora](https://github.com/evochora/evochora) simulation data using standard scientific Python tools. All data is fetched live via the REST API — no file downloads, no special libraries.\n\n**What you'll see:**\n1. Population dynamics over time\n2. A genome phylogenetic tree reconstructed from the simulation\n3. Organism-level analysis: which genomes are \"winning\" and why\n4. Cross-metric analysis with DuckDB SQL\n5. A Muller Plot showing how lineage clades rise and fall over evolutionary time\n\n**Requirements:** A running Evochora instance. Point `BASE_URL` below to your instance or use the public demo."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%%capture\n",
    "!pip install duckdb"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Point this to your Evochora instance\nBASE_URL = \"https://evochora.org\"  # Public demo\n# BASE_URL = \"http://localhost:8081\"  # Local instance\n\nimport requests, json\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom matplotlib.lines import Line2D\n\ndef format_genome_hash(h):\n    \"\"\"Convert genome hash to 6-char Base62 string (matches Visualizer display).\"\"\"\n    chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n    n = int(h)\n    if n < 0:\n        n += (1 << 64)\n    result = ''\n    for _ in range(6):\n        result = chars[n % 62] + result\n        n //= 62\n    return result\n\n# Verify connection and fetch simulation metadata\nruns = requests.get(f\"{BASE_URL}/analyzer/api/runs\").json()\nticks = requests.get(f\"{BASE_URL}/visualizer/api/organisms/ticks\").json()\nmanifest = requests.get(f\"{BASE_URL}/analyzer/api/manifest\").json()\nsim_metadata = requests.get(f\"{BASE_URL}/visualizer/api/simulation/metadata\").json()\n\nTICK_INTERVAL = sim_metadata.get('samplingInterval', 1000)\n\n# Extract thermodynamic limits from resolved config\nresolved_config = json.loads(sim_metadata.get('resolvedConfigJson', '{}'))\nruntime_cfg = resolved_config.get('runtime', {}).get('organism', {})\nMAX_ENERGY = runtime_cfg.get('max-energy', 32767)\nMAX_ENTROPY = runtime_cfg.get('max-entropy', 8191)\n\nprint(f\"Connected to {BASE_URL}\")\nprint(f\"Tick range: {ticks['minTick']:,} to {ticks['maxTick']:,}\")\nprint(f\"Organism indexing interval: {TICK_INTERVAL:,}\")\nprint(f\"Max energy: {MAX_ENERGY:,}  Max entropy: {MAX_ENTROPY:,}\")\nprint(f\"\\nAvailable metrics:\")\nfor m in manifest['metrics']:\n    print(f\"  {m['id']:30s} {m['name']}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Population Dynamics\n",
    "\n",
    "The `population` metric tracks the number of living organisms, their average energy, and average entropy at each sampled tick. This is the pulse of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pop = pd.DataFrame(requests.get(\n",
    "    f\"{BASE_URL}/analyzer/api/data\",\n",
    "    params={\"metric\": \"population\", \"lod\": \"lod2\"}\n",
    ").json())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 7), sharex=True,\n",
    "                                gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "ax1.plot(pop['tick'], pop['alive_count'], color='#3c5078', linewidth=0.8)\n",
    "ax1.set_ylabel('Living Organisms')\n",
    "ax1.set_title('Population Dynamics')\n",
    "ax1.grid(alpha=0.2)\n",
    "\n",
    "ax2.plot(pop['tick'], pop['avg_energy'], color='#c8af50', linewidth=0.8, label='Avg Energy (%)')\n",
    "ax2.plot(pop['tick'], pop['avg_entropy'], color='#50a878', linewidth=0.8, label='Avg Entropy (%)')\n",
    "ax2.set_xlabel('Tick')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Peak population: {pop['alive_count'].max()}\")\n",
    "print(f\"Final population: {pop['alive_count'].iloc[-1]}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Genome Phylogenetic Tree\n",
    "\n",
    "Every time a mutation creates a new genome during reproduction, Evochora records the parent-child relationship. The Visualizer API returns the complete `genomeLineageTree` — a mapping from each genome hash to its parent genome hash.\n",
    "\n",
    "From this single data structure, we can reconstruct the entire evolutionary tree: which lineages radiated, which went extinct, and which are still alive today."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fetch organism data at the latest available tick\n",
    "latest_tick = ticks['maxTick']\n",
    "data = requests.get(f\"{BASE_URL}/visualizer/api/organisms/{latest_tick}\").json()\n",
    "\n",
    "organisms = data['organisms']\n",
    "tree_raw = data['genomeLineageTree']\n",
    "total_created = data['totalOrganismCount']\n",
    "alive = [o for o in organisms if not o['isDead']]\n",
    "\n",
    "print(f\"Simulation at tick {latest_tick:,}\")\n",
    "print(f\"  Organisms ever created:  {total_created:,}\")\n",
    "print(f\"  Currently alive:         {len(alive):,}\")\n",
    "print(f\"  Unique genomes observed: {len(tree_raw):,}\")\n",
    "\n",
    "# Build directed graph: edge from parent genome -> child genome\n",
    "G = nx.DiGraph()\n",
    "for genome, parent in tree_raw.items():\n",
    "    G.add_node(genome)\n",
    "    if parent is not None:\n",
    "        G.add_edge(parent, genome)\n",
    "\n",
    "# Count living organisms per genome\n",
    "genome_pop = {}\n",
    "for o in alive:\n",
    "    gh = o['genomeHash']\n",
    "    genome_pop[gh] = genome_pop.get(gh, 0) + 1\n",
    "\n",
    "active_genomes = set(genome_pop.keys())\n",
    "roots = [n for n in G.nodes() if G.in_degree(n) == 0]\n",
    "\n",
    "# Compute evolutionary depth for each genome\n",
    "depths = {}\n",
    "for root in roots:\n",
    "    for node in nx.descendants(G, root) | {root}:\n",
    "        try:\n",
    "            d = nx.shortest_path_length(G, root, node)\n",
    "            depths[node] = max(depths.get(node, 0), d)\n",
    "        except nx.NetworkXNoPath:\n",
    "            pass\n",
    "\n",
    "print(f\"\\n  Root genomes (primordial): {len(roots)}\")\n",
    "print(f\"  Active genomes:           {len(active_genomes)} (with living organisms)\")\n",
    "if depths:\n",
    "    print(f\"  Max evolutionary depth:   {max(depths.values())} mutations from primordial\")\n",
    "    print(f\"  Avg evolutionary depth:   {np.mean(list(depths.values())):.1f}\")\n",
    "\n",
    "# Prune: keep only paths from roots to currently active genomes\n",
    "keep = set()\n",
    "for genome in active_genomes:\n",
    "    node = genome\n",
    "    while node is not None:\n",
    "        if node in keep:\n",
    "            break\n",
    "        keep.add(node)\n",
    "        parents = list(G.predecessors(node))\n",
    "        node = parents[0] if parents else None\n",
    "\n",
    "G_pruned = G.subgraph(keep).copy()\n",
    "print(f\"\\n  Pruned to active lineages: {G_pruned.number_of_nodes()} genomes\")\n",
    "print(f\"  (only lineages leading to currently living organisms)\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def tree_layout(G, roots):\n    \"\"\"Horizontal tree layout: root on the left, leaves on the right.\"\"\"\n    pos = {}\n    leaf_cache = {}\n\n    def count_leaves(node):\n        if node in leaf_cache:\n            return leaf_cache[node]\n        children = list(G.successors(node))\n        result = 1 if not children else sum(count_leaves(c) for c in children)\n        leaf_cache[node] = result\n        return result\n\n    def place(node, top, bottom, depth):\n        children = list(G.successors(node))\n        if not children:\n            pos[node] = (depth, (top + bottom) / 2)\n            return\n        sizes = [count_leaves(c) for c in children]\n        total = sum(sizes)\n        y = top\n        for child, size in zip(children, sizes):\n            h = (bottom - top) * size / total\n            place(child, y, y + h, depth + 1)\n            y += h\n        child_ys = [pos[c][1] for c in children]\n        pos[node] = (depth, np.mean(child_ys))\n\n    total_leaves = sum(count_leaves(r) for r in roots)\n    y = 0\n    for root in roots:\n        sz = count_leaves(root)\n        h = sz / total_leaves if total_leaves > 0 else 1\n        place(root, y, y + h, 0)\n        y += h\n    return pos\n\npruned_roots = [n for n in G_pruned.nodes() if G_pruned.in_degree(n) == 0]\npos = tree_layout(G_pruned, pruned_roots)\n\n# Node styling: gold = active genome, gray = extinct ancestor\nnode_sizes = [max(40, genome_pop.get(n, 0) * 15) for n in G_pruned.nodes()]\nnode_colors = ['#c8af50' if n in active_genomes else '#bbbbbb' for n in G_pruned.nodes()]\n\nheight = max(10, len(active_genomes) * 0.15)\nfig, ax = plt.subplots(figsize=(16, height))\nnx.draw(G_pruned, pos, ax=ax,\n        node_size=node_sizes, node_color=node_colors,\n        edge_color='#cccccc', width=0.5,\n        arrows=False, with_labels=False)\n\nax.set_title(\n    f'Genome Phylogenetic Tree — Active Lineages\\n'\n    f'{G_pruned.number_of_nodes()} genomes across '\n    f'{len(active_genomes)} active lineages '\n    f'({len(alive)} living organisms)',\n    fontsize=14, pad=20)\n\nlegend = [\n    Line2D([0], [0], marker='o', color='w', markerfacecolor='#c8af50',\n           markersize=12, label=f'Active genome ({len(active_genomes)})'),\n    Line2D([0], [0], marker='o', color='w', markerfacecolor='#bbbbbb',\n           markersize=8, label=f'Extinct ancestor ({G_pruned.number_of_nodes() - len(active_genomes)})'),\n]\nax.legend(handles=legend, loc='upper left', fontsize=11)\nplt.tight_layout()\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Each gold node is a genome with living organisms right now. Gray nodes are extinct ancestors — genomes that no longer have any living carriers but whose mutations led to the genomes alive today. The tree reads left to right: root (primordial genome) on the left, most recent mutations on the right.\n\nNode size reflects how many organisms carry that genome. Branches that split early and spread wide indicate successful evolutionary radiations.\n\n---\n## 3. Population Census\n\nWhich genomes dominate the population? How old are their organisms? Do different genomes show different survival characteristics? Let's look at the living organisms grouped by genome."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Group living organisms by genome\ngenome_stats = {}\nfor o in alive:\n    gh = o['genomeHash']\n    age = latest_tick - o['birthTick']\n    genome_stats.setdefault(gh, []).append({\n        'age': age,\n        'energy_pct': o['energy'] / MAX_ENERGY * 100,\n        'entropy_pct': o['entropyRegister'] / MAX_ENTROPY * 100\n    })\n\n# Sort by population size\ntop = sorted(genome_stats.items(), key=lambda x: -len(x[1]))[:10]\ncolors = plt.cm.tab10(np.linspace(0, 1, len(top)))\n\nfig, axes = plt.subplots(1, 4, figsize=(22, 6))\n\nlabels = [format_genome_hash(gh) for gh, _ in top]\ncounts = [len(orgs) for _, orgs in top]\n\n# Population\naxes[0].barh(labels, counts, color=colors)\naxes[0].set_xlabel('Living Organisms')\naxes[0].set_title('Top 10 Genomes by Population')\naxes[0].invert_yaxis()\n\n# Average age\navg_ages = [np.mean([o['age'] for o in orgs]) for _, orgs in top]\naxes[1].barh(labels, avg_ages, color=colors)\naxes[1].set_xlabel('Average Age (ticks)')\naxes[1].set_title('Average Organism Age')\naxes[1].invert_yaxis()\n\n# Average energy %\navg_energy = [np.mean([o['energy_pct'] for o in orgs]) for _, orgs in top]\naxes[2].barh(labels, avg_energy, color=colors)\naxes[2].set_xlabel('Average Energy (%)')\naxes[2].set_title('Average Energy')\naxes[2].invert_yaxis()\n\n# Average entropy %\navg_entropy = [np.mean([o['entropy_pct'] for o in orgs]) for _, orgs in top]\naxes[3].barh(labels, avg_entropy, color=colors)\naxes[3].set_xlabel('Average Entropy (%)')\naxes[3].set_title('Average Entropy')\naxes[3].invert_yaxis()\n\nplt.suptitle(f'Population Census at Tick {latest_tick:,}', fontsize=14, y=1.02)\nplt.tight_layout()\nplt.show()\n\n# Summary table\nprint(f\"{'Genome':>8s}  {'Pop':>5s}  {'Avg Age':>12s}  {'Energy %':>9s}  {'Entropy %':>10s}  {'Depth':>6s}\")\nprint('-' * 60)\nfor gh, orgs in top:\n    avg_a = np.mean([o['age'] for o in orgs])\n    avg_e = np.mean([o['energy_pct'] for o in orgs])\n    avg_s = np.mean([o['entropy_pct'] for o in orgs])\n    d = depths.get(gh, '?')\n    print(f\"{format_genome_hash(gh):>8s}  {len(orgs):5d}  {avg_a:12,.0f}  {avg_e:8.1f}%  {avg_s:9.1f}%  {d:>6}\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cross-Metric Analysis with DuckDB\n",
    "\n",
    "The built-in Analyzer dashboard shows each metric independently. With DuckDB, we can join metrics and ask questions that span multiple datasets — something the dashboard can't do.\n",
    "\n",
    "**Question:** Is there a relationship between population size and genome diversity? Population genetics predicts that larger populations should sustain more genetic diversity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import duckdb\n",
    "\n",
    "# Fetch genome diversity metric\n",
    "div = pd.DataFrame(requests.get(\n",
    "    f\"{BASE_URL}/analyzer/api/data\",\n",
    "    params={\"metric\": \"genome_diversity\", \"lod\": \"lod2\"}\n",
    ").json())\n",
    "\n",
    "# DuckDB: join population and diversity by tick\n",
    "con = duckdb.connect()\n",
    "con.register('population', pop)\n",
    "con.register('diversity', div)\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT p.tick,\n",
    "           p.alive_count,\n",
    "           d.shannon_index,\n",
    "           d.active_genomes,\n",
    "           d.dominant_share\n",
    "    FROM population p\n",
    "    JOIN diversity d ON p.tick = d.tick\n",
    "    WHERE p.alive_count > 0\n",
    "    ORDER BY p.tick\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: population size vs diversity (colored by time)\n",
    "sc = axes[0].scatter(result['alive_count'], result['shannon_index'],\n",
    "                     c=result['tick'], cmap='viridis', s=12, alpha=0.7)\n",
    "plt.colorbar(sc, ax=axes[0], label='Tick')\n",
    "axes[0].set_xlabel('Population Size')\n",
    "axes[0].set_ylabel('Shannon Diversity Index')\n",
    "axes[0].set_title('Population Size vs. Genome Diversity')\n",
    "axes[0].grid(alpha=0.2)\n",
    "\n",
    "# Right: dominant genome share over time\n",
    "axes[1].fill_between(result['tick'], result['dominant_share'] * 100,\n",
    "                     alpha=0.3, color='#3c5078')\n",
    "axes[1].plot(result['tick'], result['dominant_share'] * 100,\n",
    "             color='#3c5078', linewidth=0.8)\n",
    "axes[1].set_xlabel('Tick')\n",
    "axes[1].set_ylabel('Dominant Genome Share (%)')\n",
    "axes[1].set_title('How dominant is the most common genome?')\n",
    "axes[1].grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "corr = result[['alive_count', 'shannon_index']].corr().iloc[0, 1]\n",
    "print(f\"Pearson correlation (population vs. diversity): {corr:.3f}\")\n",
    "print(f\"Lowest dominant share:  {result['dominant_share'].min() * 100:.1f}%\")\n",
    "print(f\"Highest dominant share: {result['dominant_share'].max() * 100:.1f}%\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 5. Muller Plot — Evolutionary Dynamics Over Time\n\nA [Muller Plot](https://en.wikipedia.org/wiki/Muller_plot) is the gold standard visualization in experimental evolution research. It shows how different lineages rise and fall over time as nested stacked areas — child lineages are visually nested inside their parents, making it easy to see how new mutations emerge *within* an existing population and either take over or go extinct.\n\n**Challenge:** Evochora simulations produce extreme genetic diversity — thousands of unique genomes, most differing by just one or two neutral mutations. Tracking every individual genome would produce visual noise. Instead, we group genomes into **clades** (lineage families) by walking up the phylogenetic tree to a common ancestor at a certain depth. The algorithm automatically selects the depth that produces a readable number of clades.\n\nThis cell samples the Visualizer API at ~200 time points. Expect it to run for 1-2 minutes depending on your simulation size.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from collections import Counter\nfrom matplotlib.patches import Patch\nimport sys\n\n# --- Configuration ---\nN_SAMPLES = 200       # Time points to sample via Visualizer API\nCLADE_THRESHOLD = 0.02  # Track clades reaching ≥2% of population at any tick\nSMOOTH_WINDOW = 5     # Moving average window for visual smoothing\n\n# --- 1. Determine sampling range ---\n# Start from when population is established (>10 organisms)\nstart_tick = int(pop.loc[pop['alive_count'] > 10, 'tick'].iloc[0])\nend_tick = ticks['maxTick']\n\n# Align sample ticks to the organism indexing interval (from metadata)\nraw_ticks = np.linspace(start_tick, end_tick, N_SAMPLES)\nsample_ticks = sorted(set(int(round(t / TICK_INTERVAL) * TICK_INTERVAL) for t in raw_ticks))\nn_samples = len(sample_ticks)\nprint(f\"Sampling {n_samples} ticks from {start_tick:,} to {end_tick:,} (interval: {TICK_INTERVAL:,})\")\n\n# --- 2. Fetch organism counts per genome at each sample tick ---\nfreq_raw = {}\nfor i, t in enumerate(sample_ticks):\n    resp = requests.get(f\"{BASE_URL}/visualizer/api/organisms/{t}\").json()\n    counts = {}\n    for o in resp['organisms']:\n        if not o.get('isDead', False):\n            counts[o['genomeHash']] = counts.get(o['genomeHash'], 0) + 1\n    freq_raw[t] = counts\n    if (i + 1) % 50 == 0 or i == n_samples - 1:\n        total = sum(counts.values())\n        print(f\"  {i+1}/{n_samples} — tick {t:>12,}: {total} organisms, {len(counts)} genomes\")\n\ntotal_ot = sum(sum(c.values()) for c in freq_raw.values())\n\n# --- 3. Compute evolutionary depth for every genome (fast BFS) ---\nfull_depths = {}\nfor root in roots:\n    full_depths[root] = 0\n    for u, v in nx.bfs_edges(G, root):\n        full_depths[v] = full_depths[u] + 1\n\nmax_depth = max(full_depths.values()) if full_depths else 0\n\ndef get_ancestor(genome, target_depth):\n    \"\"\"Walk up the lineage tree to find ancestor at target_depth.\"\"\"\n    d = full_depths.get(genome, 0)\n    node = genome\n    while d > target_depth and node in G:\n        parents = list(G.predecessors(node))\n        if not parents:\n            break\n        node = parents[0]\n        d = full_depths.get(node, 0)\n    return node\n\n# --- 4. Auto-select clade depth ---\n# Find the depth that produces 10-40 significant clades (>0.5% of total)\nbest_depth = max_depth // 3  # fallback\nfor try_depth in range(1, max_depth):\n    clade_totals_trial = {}\n    for counts in freq_raw.values():\n        for gh, c in counts.items():\n            anc = get_ancestor(gh, try_depth)\n            clade_totals_trial[anc] = clade_totals_trial.get(anc, 0) + c\n    sig = sum(1 for v in clade_totals_trial.values() if v / total_ot > 0.005)\n    if 10 <= sig <= 40:\n        best_depth = try_depth\n        break\n    elif sig > 40:\n        best_depth = max(1, try_depth - 1)\n        break\n\nprint(f\"\\nAuto-selected clade depth: {best_depth} (max tree depth: {max_depth})\")\n\n# --- 5. Group genomes into clades ---\nfreq = {}\nfor t, counts in freq_raw.items():\n    clade_counts = {}\n    for gh, c in counts.items():\n        anc = get_ancestor(gh, best_depth)\n        clade_counts[anc] = clade_counts.get(anc, 0) + c\n    freq[t] = clade_counts\n\n# Select significant clades\nclade_set = set()\nfor t, counts in freq.items():\n    total = sum(counts.values())\n    if total > 0:\n        for clade, c in counts.items():\n            if c / total >= CLADE_THRESHOLD:\n                clade_set.add(clade)\n\nclade_totals = {}\nfor counts in freq.values():\n    for clade, c in counts.items():\n        clade_totals[clade] = clade_totals.get(clade, 0) + c\n\ntracked_ot = sum(clade_totals.get(c, 0) for c in clade_set)\nprint(f\"Tracking {len(clade_set)} clades: \"\n      f\"{tracked_ot}/{total_ot} organism-ticks ({100*tracked_ot/total_ot:.0f}%)\")\n\n# --- 6. Build clade subtree + Euler tour ---\nrelevant = set()\nfor c in clade_set:\n    node = c\n    while node is not None:\n        if node in relevant:\n            break\n        relevant.add(node)\n        if node not in G:\n            break\n        parents = list(G.predecessors(node))\n        node = parents[0] if parents else None\n\nG_clade = G.subgraph(relevant).copy()\nclade_roots = sorted(n for n in G_clade.nodes() if G_clade.in_degree(n) == 0)\n\nsys.setrecursionlimit(10000)\ntour = []\ndef euler_visit(node):\n    children = sorted(G_clade.successors(node))\n    if not children:\n        tour.append(node)\n    else:\n        tour.append(node)\n        for child in children:\n            euler_visit(child)\n        tour.append(node)\n\nfor root in clade_roots:\n    euler_visit(root)\nappearances = Counter(tour)\n\n# --- 7. Compute stacked values ---\ntick_arr = np.array(sample_ticks, dtype=float)\n\ndef smooth(arr, window):\n    \"\"\"Simple moving average smoothing.\"\"\"\n    if window <= 1:\n        return arr\n    kernel = np.ones(window) / window\n    return np.convolve(arr, kernel, mode='same')\n\nstacked = np.zeros((len(tour), n_samples))\nfor tick_idx, t in enumerate(sample_ticks):\n    counts = freq[t]\n    for tour_idx, clade in enumerate(tour):\n        stacked[tour_idx, tick_idx] = counts.get(clade, 0) / appearances[clade]\n\nfor row in range(stacked.shape[0]):\n    stacked[row] = smooth(stacked[row], SMOOTH_WINDOW)\n\ncumulative = np.cumsum(stacked, axis=0)\ncum_with_zero = np.vstack([np.zeros((1, n_samples)), cumulative])\n\nother_raw = np.zeros(n_samples)\nfor tick_idx, t in enumerate(sample_ticks):\n    total = sum(freq_raw[t].values())\n    tracked = sum(freq[t].get(c, 0) for c in relevant)\n    other_raw[tick_idx] = total - tracked\nother = smooth(other_raw, SMOOTH_WINDOW)\n\n# Depths for z-ordering (parents behind, children in front)\nclade_depths = {}\nfor root in clade_roots:\n    clade_depths[root] = 0\n    for u, v in nx.bfs_edges(G_clade, root):\n        clade_depths[v] = clade_depths[u] + 1\n\n# --- 8. Colors (Tableau 20 palette) ---\nPALETTE = [\n    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n    '#8c564b', '#e377c2', '#bcbd22', '#17becf', '#aec7e8',\n    '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5', '#c49c94',\n    '#f7b6d2', '#dbdb8d', '#9edae5', '#393b79', '#637939',\n]\n\nclade_colors = {}\nsorted_clades = sorted(clade_set, key=lambda x: -clade_totals.get(x, 0))\nfor i, c in enumerate(sorted_clades):\n    clade_colors[c] = PALETTE[i % len(PALETTE)]\nfor c in relevant - clade_set:\n    clade_colors[c] = '#d4d4d8'\n\n# --- 9. Plot ---\nfig, ax = plt.subplots(figsize=(18, 8))\n\n# \"Other\" band on top\ntotal_tracked = cumulative[-1]\nax.fill_between(tick_arr, total_tracked, total_tracked + other,\n                facecolor='#e8e8e8', edgecolor='#f0f0f0', linewidth=0.1)\n\n# Clade bands: parents first (behind), children in front\nfor clade in sorted(set(tour), key=lambda g: clade_depths.get(g, 0)):\n    indices = [i for i, g in enumerate(tour) if g == clade]\n    bottom = cum_with_zero[indices[0]]\n    top = cumulative[indices[-1]]\n    ax.fill_between(tick_arr, bottom, top,\n                     facecolor=clade_colors.get(clade, '#aaaaaa'),\n                     edgecolor='white', linewidth=0.2)\n\nax.set_xlabel('Tick', fontsize=13)\nax.set_ylabel('Living Organisms', fontsize=13)\nax.set_xlim(tick_arr[0], tick_arr[-1])\nax.set_ylim(0, None)\nax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x/1e6:.0f}M'))\n\n# Legend: top 8 clades + \"Other\"\nlegend_clades = sorted_clades[:8]\nhandles = [Patch(facecolor=clade_colors[c], label=f'Clade {format_genome_hash(c)}')\n           for c in legend_clades]\nhandles.append(Patch(facecolor='#e8e8e8',\n                     label=f'Other ({len(tree_raw) - len(clade_set):,} genomes)'))\nax.legend(handles=handles, loc='upper left', fontsize=9, framealpha=0.9)\n\nax.set_title(\n    f'Muller Plot — Lineage Clade Dynamics\\n'\n    f'{len(clade_set)} clades (grouped at depth {best_depth}) '\n    f'from {len(tree_raw):,} genomes',\n    fontsize=14)\n\nplt.tight_layout()\nplt.show()\n\n# Summary\nprint(f\"\\nTop clades by total organism-ticks:\")\nfor i, c in enumerate(sorted_clades[:10]):\n    pct = 100 * clade_totals[c] / total_ot\n    print(f\"  {i+1}. {format_genome_hash(c):>6s}  {clade_totals[c]:6,} ({pct:4.1f}%)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working With Local Parquet Files\n",
    "\n",
    "When running your own simulations, you can skip the REST API entirely and point DuckDB directly at the Parquet files on disk. This is the most powerful pattern for large-scale analysis:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "---\n## What's Next\n\nThis notebook covers the basics. Here are some directions to explore:\n\n- **Survival Curves** — Build Kaplan-Meier curves by sampling organisms across multiple ticks to measure lineage half-life.\n- **Fitness Landscape** — Use the phylogenetic tree + organism fitness data to map the adaptive landscape the population is navigating.\n- **Custom Analytics Plugins** — Write your own metrics in Java that get exported as Parquet automatically. See the [Contributing Guide](https://github.com/evochora/evochora/blob/main/CONTRIBUTING.md).\n\nFor more details, see the [Scientific Overview](https://github.com/evochora/evochora/blob/main/docs/SCIENTIFIC_OVERVIEW.md) and the [Assembly Specification](https://github.com/evochora/evochora/blob/main/docs/ASSEMBLY_SPEC.md).",
   "execution_count": null,
   "outputs": []
  }
 ]
}