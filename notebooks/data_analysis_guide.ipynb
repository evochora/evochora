{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evochora — Data Analysis Guide\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/evochora/evochora/blob/main/notebooks/data_analysis_guide.ipynb?flush_cache=true)\n",
    "\n",
    "This notebook shows how to analyze [Evochora](https://github.com/evochora/evochora) simulation data using standard scientific Python tools. All data is fetched live via the REST API — no file downloads, no special libraries.\n",
    "\n",
    "**What you'll see:**\n",
    "1. Population dynamics over time\n",
    "2. A genome phylogenetic tree reconstructed from the simulation\n",
    "3. Organism-level analysis: which genomes are \"winning\" and why\n",
    "4. Cross-metric analysis with DuckDB SQL\n",
    "5. A Muller Plot showing how lineage clades rise and fall over evolutionary time\n",
    "\n",
    "**Requirements:** A running Evochora instance. Point `BASE_URL` below to your instance or use the public demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point this to your Evochora instance\n",
    "BASE_URL = \"https://evochora.org\"  # Public demo\n",
    "# BASE_URL = \"http://localhost:8081\"  # Local instance\n",
    "\n",
    "# Override auto-selection: uncomment and set a specific run ID\n",
    "# RUN_ID = \"20260216-21270780-fc077723-...\"\n",
    "\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def format_genome_hash(h):\n",
    "    \"\"\"Convert genome hash to 6-char Base62 string (matches Visualizer display).\"\"\"\n",
    "    chars = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    n = int(h)\n",
    "    if n < 0:\n",
    "        n += (1 << 64)\n",
    "    result = ''\n",
    "    for _ in range(6):\n",
    "        result = chars[n % 62] + result\n",
    "        n //= 62\n",
    "    return result\n",
    "\n",
    "# Select the simulation run to analyze\n",
    "runs = requests.get(f\"{BASE_URL}/analyzer/api/runs\").json()\n",
    "\n",
    "if 'RUN_ID' in dir() and RUN_ID:\n",
    "    # Manual selection: verify the run exists\n",
    "    valid_ids = {r['runId'] for r in runs}\n",
    "    if RUN_ID not in valid_ids:\n",
    "        print(f\"WARNING: Run ID '{RUN_ID}' not found. Available runs:\")\n",
    "        for r in runs:\n",
    "            print(f\"  {r['runId']}\")\n",
    "        raise ValueError(f\"Run ID '{RUN_ID}' not found on {BASE_URL}\")\n",
    "    print(f\"Using manually selected run: {RUN_ID}\")\n",
    "elif len(runs) > 1:\n",
    "    # Auto-select: pick the run with the highest maxTick\n",
    "    best_run = None\n",
    "    best_max_tick = -1\n",
    "    for r in runs:\n",
    "        t = requests.get(f\"{BASE_URL}/visualizer/api/organisms/ticks\",\n",
    "                         params={\"runId\": r['runId']}).json()\n",
    "        if t['maxTick'] > best_max_tick:\n",
    "            best_max_tick = t['maxTick']\n",
    "            best_run = r['runId']\n",
    "    RUN_ID = best_run\n",
    "    print(f\"Auto-selected run {RUN_ID} ({best_max_tick:,} ticks) from {len(runs)} available runs\")\n",
    "else:\n",
    "    RUN_ID = runs[0]['runId']\n",
    "\n",
    "# Helper: add runId to all API requests\n",
    "run_params = {\"runId\": RUN_ID}\n",
    "\n",
    "ticks = requests.get(f\"{BASE_URL}/visualizer/api/organisms/ticks\", params=run_params).json()\n",
    "manifest = requests.get(f\"{BASE_URL}/analyzer/api/manifest\", params=run_params).json()\n",
    "sim_metadata = requests.get(f\"{BASE_URL}/visualizer/api/simulation/metadata\", params=run_params).json()\n",
    "\n",
    "TICK_INTERVAL = sim_metadata.get('samplingInterval', 1000)\n",
    "\n",
    "# Extract thermodynamic limits from resolved config\n",
    "resolved_config = json.loads(sim_metadata.get('resolvedConfigJson', '{}'))\n",
    "runtime_cfg = resolved_config.get('runtime', {}).get('organism', {})\n",
    "MAX_ENERGY = runtime_cfg.get('max-energy', 32767)\n",
    "MAX_ENTROPY = runtime_cfg.get('max-entropy', 8191)\n",
    "\n",
    "print(f\"Connected to {BASE_URL}\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(f\"Tick range: {ticks['minTick']:,} to {ticks['maxTick']:,}\")\n",
    "print(f\"Organism indexing interval: {TICK_INTERVAL:,}\")\n",
    "print(f\"Max energy: {MAX_ENERGY:,}  Max entropy: {MAX_ENTROPY:,}\")\n",
    "print(f\"\\nAvailable metrics:\")\n",
    "for m in manifest['metrics']:\n",
    "    print(f\"  {m['id']:30s} {m['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Population Dynamics\n",
    "\n",
    "The `population` metric tracks the number of living organisms, their average energy, and average entropy at each sampled tick. This is the pulse of the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pd.DataFrame(requests.get(\n",
    "    f\"{BASE_URL}/analyzer/api/data\",\n",
    "    params={**run_params, \"metric\": \"population\", \"lod\": \"lod2\"}\n",
    ").json())\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 7), sharex=True,\n",
    "                                gridspec_kw={'height_ratios': [2, 1]})\n",
    "\n",
    "ax1.plot(pop['tick'], pop['alive_count'], color='#3c5078', linewidth=0.8)\n",
    "ax1.set_ylabel('Living Organisms')\n",
    "ax1.set_title('Population Dynamics')\n",
    "ax1.grid(alpha=0.2)\n",
    "\n",
    "ax2.plot(pop['tick'], pop['avg_energy'], color='#c8af50', linewidth=0.8, label='Avg Energy (%)')\n",
    "ax2.plot(pop['tick'], pop['avg_entropy'], color='#50a878', linewidth=0.8, label='Avg Entropy (%)')\n",
    "ax2.set_xlabel('Tick')\n",
    "ax2.set_ylabel('Percentage')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Peak population: {pop['alive_count'].max()}\")\n",
    "print(f\"Final population: {pop['alive_count'].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Genome Phylogenetic Tree\n",
    "\n",
    "Every time a mutation creates a new genome during reproduction, Evochora records the parent-child relationship. The Visualizer API returns the complete `genomeLineageTree` — a mapping from each genome hash to its parent genome hash.\n",
    "\n",
    "From this single data structure, we can reconstruct the entire evolutionary tree: which lineages radiated, which went extinct, and which are still alive today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch organism data at the latest available tick\n",
    "latest_tick = ticks['maxTick']\n",
    "data = requests.get(f\"{BASE_URL}/visualizer/api/organisms/{latest_tick}\", params=run_params).json()\n",
    "\n",
    "organisms = data['organisms']\n",
    "tree_raw = data['genomeLineageTree']\n",
    "total_created = data['totalOrganismCount']\n",
    "alive = [o for o in organisms if not o['isDead']]\n",
    "\n",
    "print(f\"Simulation at tick {latest_tick:,}\")\n",
    "print(f\"  Organisms ever created:  {total_created:,}\")\n",
    "print(f\"  Currently alive:         {len(alive):,}\")\n",
    "print(f\"  Unique genomes observed: {len(tree_raw):,}\")\n",
    "\n",
    "# Build directed graph: edge from parent genome -> child genome\n",
    "G = nx.DiGraph()\n",
    "for genome, parent in tree_raw.items():\n",
    "    G.add_node(genome)\n",
    "    if parent is not None:\n",
    "        G.add_edge(parent, genome)\n",
    "\n",
    "# Count living organisms per genome\n",
    "genome_pop = {}\n",
    "for o in alive:\n",
    "    gh = o['genomeHash']\n",
    "    genome_pop[gh] = genome_pop.get(gh, 0) + 1\n",
    "\n",
    "active_genomes = set(genome_pop.keys())\n",
    "roots = [n for n in G.nodes() if G.in_degree(n) == 0]\n",
    "\n",
    "# Compute evolutionary depth for each genome\n",
    "depths = {}\n",
    "for root in roots:\n",
    "    for node in nx.descendants(G, root) | {root}:\n",
    "        try:\n",
    "            d = nx.shortest_path_length(G, root, node)\n",
    "            depths[node] = max(depths.get(node, 0), d)\n",
    "        except nx.NetworkXNoPath:\n",
    "            pass\n",
    "\n",
    "print(f\"\\n  Root genomes (primordial): {len(roots)}\")\n",
    "print(f\"  Active genomes:           {len(active_genomes)} (with living organisms)\")\n",
    "if depths:\n",
    "    print(f\"  Max evolutionary depth:   {max(depths.values())} mutations from primordial\")\n",
    "    print(f\"  Avg evolutionary depth:   {np.mean(list(depths.values())):.1f}\")\n",
    "\n",
    "# Prune: keep only paths from roots to currently active genomes\n",
    "keep = set()\n",
    "for genome in active_genomes:\n",
    "    node = genome\n",
    "    while node is not None:\n",
    "        if node in keep:\n",
    "            break\n",
    "        keep.add(node)\n",
    "        parents = list(G.predecessors(node))\n",
    "        node = parents[0] if parents else None\n",
    "\n",
    "G_pruned = G.subgraph(keep).copy()\n",
    "print(f\"\\n  Pruned to active lineages: {G_pruned.number_of_nodes()} genomes\")\n",
    "print(f\"  (only lineages leading to currently living organisms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_layout(G, roots):\n",
    "    \"\"\"Horizontal tree layout: root on the left, leaves on the right.\"\"\"\n",
    "    pos = {}\n",
    "    leaf_cache = {}\n",
    "\n",
    "    def count_leaves(node):\n",
    "        if node in leaf_cache:\n",
    "            return leaf_cache[node]\n",
    "        children = list(G.successors(node))\n",
    "        result = 1 if not children else sum(count_leaves(c) for c in children)\n",
    "        leaf_cache[node] = result\n",
    "        return result\n",
    "\n",
    "    def place(node, top, bottom, depth):\n",
    "        children = list(G.successors(node))\n",
    "        if not children:\n",
    "            pos[node] = (depth, (top + bottom) / 2)\n",
    "            return\n",
    "        sizes = [count_leaves(c) for c in children]\n",
    "        total = sum(sizes)\n",
    "        y = top\n",
    "        for child, size in zip(children, sizes):\n",
    "            h = (bottom - top) * size / total\n",
    "            place(child, y, y + h, depth + 1)\n",
    "            y += h\n",
    "        child_ys = [pos[c][1] for c in children]\n",
    "        pos[node] = (depth, np.mean(child_ys))\n",
    "\n",
    "    total_leaves = sum(count_leaves(r) for r in roots)\n",
    "    y = 0\n",
    "    for root in roots:\n",
    "        sz = count_leaves(root)\n",
    "        h = sz / total_leaves if total_leaves > 0 else 1\n",
    "        place(root, y, y + h, 0)\n",
    "        y += h\n",
    "    return pos\n",
    "\n",
    "pruned_roots = [n for n in G_pruned.nodes() if G_pruned.in_degree(n) == 0]\n",
    "pos = tree_layout(G_pruned, pruned_roots)\n",
    "\n",
    "# Node styling: gold = active genome, gray = extinct ancestor\n",
    "node_sizes = [max(40, genome_pop.get(n, 0) * 15) for n in G_pruned.nodes()]\n",
    "node_colors = ['#c8af50' if n in active_genomes else '#bbbbbb' for n in G_pruned.nodes()]\n",
    "\n",
    "height = max(10, len(active_genomes) * 0.15)\n",
    "fig, ax = plt.subplots(figsize=(16, height))\n",
    "nx.draw(G_pruned, pos, ax=ax,\n",
    "        node_size=node_sizes, node_color=node_colors,\n",
    "        edge_color='#cccccc', width=0.5,\n",
    "        arrows=False, with_labels=False)\n",
    "\n",
    "ax.set_title(\n",
    "    f'Genome Phylogenetic Tree — Active Lineages\\n'\n",
    "    f'{G_pruned.number_of_nodes()} genomes across '\n",
    "    f'{len(active_genomes)} active lineages '\n",
    "    f'({len(alive)} living organisms)',\n",
    "    fontsize=14, pad=20)\n",
    "\n",
    "legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#c8af50',\n",
    "           markersize=12, label=f'Active genome ({len(active_genomes)})'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#bbbbbb',\n",
    "           markersize=8, label=f'Extinct ancestor ({G_pruned.number_of_nodes() - len(active_genomes)})'),\n",
    "]\n",
    "ax.legend(handles=legend, loc='upper left', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each gold node is a genome with living organisms right now. Gray nodes are extinct ancestors — genomes that no longer have any living carriers but whose mutations led to the genomes alive today. The tree reads left to right: root (primordial genome) on the left, most recent mutations on the right.\n",
    "\n",
    "Node size reflects how many organisms carry that genome. Branches that split early and spread wide indicate successful evolutionary radiations.\n",
    "\n",
    "---\n",
    "## 3. Population Census\n",
    "\n",
    "Which genomes dominate the population? How old are their organisms? Do different genomes show different survival characteristics? Let's look at the living organisms grouped by genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group living organisms by genome\n",
    "genome_stats = {}\n",
    "for o in alive:\n",
    "    gh = o['genomeHash']\n",
    "    age = latest_tick - o['birthTick']\n",
    "    genome_stats.setdefault(gh, []).append({\n",
    "        'age': age,\n",
    "        'energy_pct': o['energy'] / MAX_ENERGY * 100,\n",
    "        'entropy_pct': o['entropyRegister'] / MAX_ENTROPY * 100\n",
    "    })\n",
    "\n",
    "# Sort by population size\n",
    "top = sorted(genome_stats.items(), key=lambda x: -len(x[1]))[:10]\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(top)))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 6))\n",
    "\n",
    "labels = [format_genome_hash(gh) for gh, _ in top]\n",
    "counts = [len(orgs) for _, orgs in top]\n",
    "\n",
    "# Population\n",
    "axes[0].barh(labels, counts, color=colors)\n",
    "axes[0].set_xlabel('Living Organisms')\n",
    "axes[0].set_title('Top 10 Genomes by Population')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Average age\n",
    "avg_ages = [np.mean([o['age'] for o in orgs]) for _, orgs in top]\n",
    "axes[1].barh(labels, avg_ages, color=colors)\n",
    "axes[1].set_xlabel('Average Age (ticks)')\n",
    "axes[1].set_title('Average Organism Age')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# Average energy %\n",
    "avg_energy = [np.mean([o['energy_pct'] for o in orgs]) for _, orgs in top]\n",
    "axes[2].barh(labels, avg_energy, color=colors)\n",
    "axes[2].set_xlabel('Average Energy (%)')\n",
    "axes[2].set_title('Average Energy')\n",
    "axes[2].invert_yaxis()\n",
    "\n",
    "# Average entropy %\n",
    "avg_entropy = [np.mean([o['entropy_pct'] for o in orgs]) for _, orgs in top]\n",
    "axes[3].barh(labels, avg_entropy, color=colors)\n",
    "axes[3].set_xlabel('Average Entropy (%)')\n",
    "axes[3].set_title('Average Entropy')\n",
    "axes[3].invert_yaxis()\n",
    "\n",
    "plt.suptitle(f'Population Census at Tick {latest_tick:,}', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(f\"{'Genome':>8s}  {'Pop':>5s}  {'Avg Age':>12s}  {'Energy %':>9s}  {'Entropy %':>10s}  {'Depth':>6s}\")\n",
    "print('-' * 60)\n",
    "for gh, orgs in top:\n",
    "    avg_a = np.mean([o['age'] for o in orgs])\n",
    "    avg_e = np.mean([o['energy_pct'] for o in orgs])\n",
    "    avg_s = np.mean([o['entropy_pct'] for o in orgs])\n",
    "    d = depths.get(gh, '?')\n",
    "    print(f\"{format_genome_hash(gh):>8s}  {len(orgs):5d}  {avg_a:12,.0f}  {avg_e:8.1f}%  {avg_s:9.1f}%  {d:>6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Cross-Metric Analysis with DuckDB\n",
    "\n",
    "The built-in Analyzer dashboard shows each metric independently. With DuckDB, we can join metrics and ask questions that span multiple datasets — something the dashboard can't do.\n",
    "\n",
    "**Question:** Is there a relationship between population size and genome diversity? Population genetics predicts that larger populations should sustain more genetic diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "# Fetch genome diversity metric\n",
    "div = pd.DataFrame(requests.get(\n",
    "    f\"{BASE_URL}/analyzer/api/data\",\n",
    "    params={**run_params, \"metric\": \"genome_diversity\", \"lod\": \"lod2\"}\n",
    ").json())\n",
    "\n",
    "# DuckDB: join population and diversity by tick\n",
    "con = duckdb.connect()\n",
    "con.register('population', pop)\n",
    "con.register('diversity', div)\n",
    "\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT p.tick,\n",
    "           p.alive_count,\n",
    "           d.shannon_index,\n",
    "           d.active_genomes,\n",
    "           d.dominant_share\n",
    "    FROM population p\n",
    "    JOIN diversity d ON p.tick = d.tick\n",
    "    WHERE p.alive_count > 0\n",
    "    ORDER BY p.tick\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Left: population size vs diversity (colored by time)\n",
    "sc = axes[0].scatter(result['alive_count'], result['shannon_index'],\n",
    "                     c=result['tick'], cmap='viridis', s=12, alpha=0.7)\n",
    "plt.colorbar(sc, ax=axes[0], label='Tick')\n",
    "axes[0].set_xlabel('Population Size')\n",
    "axes[0].set_ylabel('Shannon Diversity Index')\n",
    "axes[0].set_title('Population Size vs. Genome Diversity')\n",
    "axes[0].grid(alpha=0.2)\n",
    "\n",
    "# Right: dominant genome share over time\n",
    "axes[1].fill_between(result['tick'], result['dominant_share'] * 100,\n",
    "                     alpha=0.3, color='#3c5078')\n",
    "axes[1].plot(result['tick'], result['dominant_share'] * 100,\n",
    "             color='#3c5078', linewidth=0.8)\n",
    "axes[1].set_xlabel('Tick')\n",
    "axes[1].set_ylabel('Dominant Genome Share (%)')\n",
    "axes[1].set_title('How dominant is the most common genome?')\n",
    "axes[1].grid(alpha=0.2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "corr = result[['alive_count', 'shannon_index']].corr().iloc[0, 1]\n",
    "print(f\"Pearson correlation (population vs. diversity): {corr:.3f}\")\n",
    "print(f\"Lowest dominant share:  {result['dominant_share'].min() * 100:.1f}%\")\n",
    "print(f\"Highest dominant share: {result['dominant_share'].max() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Muller Plot — Evolutionary Dynamics Over Time\n",
    "\n",
    "A [Muller Plot](https://en.wikipedia.org/wiki/Muller_plot) is the gold standard visualization in experimental evolution research. It shows how different lineages rise and fall over time as nested stacked areas — child lineages are visually nested inside their parents, making it easy to see how new mutations emerge *within* an existing population and either take over or go extinct.\n",
    "\n",
    "**Challenge:** Evochora simulations produce extreme genetic diversity — thousands of unique genomes, most differing by just one or two neutral mutations. Tracking every individual genome would produce visual noise. Instead, we group genomes into **clades** (lineage families) by walking up the phylogenetic tree to a common ancestor at a certain depth. The algorithm automatically selects the depth that produces a readable number of clades.\n",
    "\n",
    "This cell samples the Visualizer API at ~200 time points. Expect it to run for 1-2 minutes depending on your simulation size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib.patches import Patch\n",
    "import sys\n",
    "\n",
    "# --- Configuration ---\n",
    "N_SAMPLES = 200       # Time points to sample via Visualizer API\n",
    "CLADE_DEPTH = None    # None = auto-select, or set manually (e.g. 8, 15, 25)\n",
    "CLADE_THRESHOLD = 0.05  # Track clades reaching ≥5% of population at any tick\n",
    "SMOOTH_WINDOW = 8     # Moving average window for visual smoothing\n",
    "\n",
    "# --- 1. Determine sampling range ---\n",
    "# Start from when population is established (>10 organisms)\n",
    "start_candidates = pop.loc[pop['alive_count'] > 10, 'tick']\n",
    "if len(start_candidates) == 0:\n",
    "    start_tick = int(pop['tick'].iloc[0])\n",
    "    print(\"WARNING: Population never exceeded 10 organisms, starting from first tick\")\n",
    "else:\n",
    "    start_tick = int(start_candidates.iloc[0])\n",
    "end_tick = ticks['maxTick']\n",
    "\n",
    "# Align sample ticks to the organism indexing interval (from metadata)\n",
    "raw_ticks = np.linspace(start_tick, end_tick, N_SAMPLES)\n",
    "sample_ticks = sorted(set(int(round(t / TICK_INTERVAL) * TICK_INTERVAL) for t in raw_ticks))\n",
    "n_samples = len(sample_ticks)\n",
    "print(f\"Sampling {n_samples} ticks from {start_tick:,} to {end_tick:,} (interval: {TICK_INTERVAL:,})\")\n",
    "\n",
    "# --- 2. Fetch organism counts per genome at each sample tick ---\n",
    "freq_raw = {}\n",
    "for i, t in enumerate(sample_ticks):\n",
    "    resp = requests.get(f\"{BASE_URL}/visualizer/api/organisms/{t}\", params=run_params).json()\n",
    "    counts = {}\n",
    "    for o in resp['organisms']:\n",
    "        if not o.get('isDead', False):\n",
    "            counts[o['genomeHash']] = counts.get(o['genomeHash'], 0) + 1\n",
    "    freq_raw[t] = counts\n",
    "    if (i + 1) % 50 == 0 or i == n_samples - 1:\n",
    "        total = sum(counts.values())\n",
    "        print(f\"  {i+1}/{n_samples} — tick {t:>12,}: {total} organisms, {len(counts)} genomes\")\n",
    "\n",
    "total_ot = sum(sum(c.values()) for c in freq_raw.values())\n",
    "\n",
    "# --- 3. Compute evolutionary depth for every genome (fast BFS) ---\n",
    "full_depths = {}\n",
    "for root in roots:\n",
    "    full_depths[root] = 0\n",
    "    for u, v in nx.bfs_edges(G, root):\n",
    "        full_depths[v] = full_depths[u] + 1\n",
    "\n",
    "max_depth = max(full_depths.values()) if full_depths else 0\n",
    "\n",
    "def get_ancestor(genome, target_depth):\n",
    "    \"\"\"Walk up the lineage tree to find ancestor at target_depth.\"\"\"\n",
    "    d = full_depths.get(genome, 0)\n",
    "    node = genome\n",
    "    while d > target_depth and node in G:\n",
    "        parents = list(G.predecessors(node))\n",
    "        if not parents:\n",
    "            break\n",
    "        node = parents[0]\n",
    "        d = full_depths.get(node, 0)\n",
    "    return node\n",
    "\n",
    "# --- 4. Select clade depth ---\n",
    "if CLADE_DEPTH is not None:\n",
    "    best_depth = CLADE_DEPTH\n",
    "    print(f\"\\nManual clade depth: {best_depth} (max tree depth: {max_depth})\")\n",
    "else:\n",
    "    # Auto-select: find the depth that produces enough clades to reveal\n",
    "    # sub-lineage dynamics across the full time range (target 120-200\n",
    "    # significant clades for a rich Muller plot with visible turnover).\n",
    "    best_depth = max(1, max_depth // 3)  # fallback\n",
    "    for try_depth in range(1, max_depth):\n",
    "        clade_peak_share = {}\n",
    "        for t, counts in freq_raw.items():\n",
    "            total = sum(counts.values())\n",
    "            if total == 0:\n",
    "                continue\n",
    "            clade_counts = {}\n",
    "            for gh, c in counts.items():\n",
    "                anc = get_ancestor(gh, try_depth)\n",
    "                clade_counts[anc] = clade_counts.get(anc, 0) + c\n",
    "            for anc, c in clade_counts.items():\n",
    "                share = c / total\n",
    "                clade_peak_share[anc] = max(clade_peak_share.get(anc, 0), share)\n",
    "        sig = sum(1 for v in clade_peak_share.values() if v >= CLADE_THRESHOLD)\n",
    "        if 120 <= sig <= 200:\n",
    "            best_depth = try_depth\n",
    "            break\n",
    "        elif sig > 200:\n",
    "            best_depth = max(1, try_depth - 1)\n",
    "            break\n",
    "    print(f\"\\nAuto-selected clade depth: {best_depth} (max tree depth: {max_depth})\")\n",
    "\n",
    "# --- 5. Group genomes into clades ---\n",
    "freq = {}\n",
    "for t, counts in freq_raw.items():\n",
    "    clade_counts = {}\n",
    "    for gh, c in counts.items():\n",
    "        anc = get_ancestor(gh, best_depth)\n",
    "        clade_counts[anc] = clade_counts.get(anc, 0) + c\n",
    "    freq[t] = clade_counts\n",
    "\n",
    "# Select significant clades (those reaching CLADE_THRESHOLD at any tick)\n",
    "clade_set = set()\n",
    "for t, counts in freq.items():\n",
    "    total = sum(counts.values())\n",
    "    if total > 0:\n",
    "        for clade, c in counts.items():\n",
    "            if c / total >= CLADE_THRESHOLD:\n",
    "                clade_set.add(clade)\n",
    "\n",
    "clade_totals = {}\n",
    "for counts in freq.values():\n",
    "    for clade, c in counts.items():\n",
    "        clade_totals[clade] = clade_totals.get(clade, 0) + c\n",
    "\n",
    "tracked_ot = sum(clade_totals.get(c, 0) for c in clade_set)\n",
    "print(f\"Tracking {len(clade_set)} clades: \"\n",
    "      f\"{tracked_ot}/{total_ot} organism-ticks ({100*tracked_ot/total_ot:.0f}%)\")\n",
    "\n",
    "# --- 6. Build clade subtree + Euler tour ---\n",
    "relevant = set()\n",
    "for c in clade_set:\n",
    "    node = c\n",
    "    while node is not None:\n",
    "        if node in relevant:\n",
    "            break\n",
    "        relevant.add(node)\n",
    "        if node not in G:\n",
    "            break\n",
    "        parents = list(G.predecessors(node))\n",
    "        node = parents[0] if parents else None\n",
    "\n",
    "G_clade = G.subgraph(relevant).copy()\n",
    "clade_roots = sorted(n for n in G_clade.nodes() if G_clade.in_degree(n) == 0)\n",
    "\n",
    "sys.setrecursionlimit(10000)\n",
    "tour = []\n",
    "def euler_visit(node):\n",
    "    children = sorted(G_clade.successors(node))\n",
    "    if not children:\n",
    "        tour.append(node)\n",
    "    else:\n",
    "        tour.append(node)\n",
    "        for child in children:\n",
    "            euler_visit(child)\n",
    "        tour.append(node)\n",
    "\n",
    "for root in clade_roots:\n",
    "    euler_visit(root)\n",
    "appearances = Counter(tour)\n",
    "\n",
    "# --- 7. Compute stacked values ---\n",
    "tick_arr = np.array(sample_ticks, dtype=float)\n",
    "\n",
    "def smooth(arr, window):\n",
    "    \"\"\"Simple moving average smoothing.\"\"\"\n",
    "    if window <= 1:\n",
    "        return arr\n",
    "    kernel = np.ones(window) / window\n",
    "    return np.convolve(arr, kernel, mode='same')\n",
    "\n",
    "stacked = np.zeros((len(tour), n_samples))\n",
    "for tick_idx, t in enumerate(sample_ticks):\n",
    "    counts = freq[t]\n",
    "    for tour_idx, clade in enumerate(tour):\n",
    "        stacked[tour_idx, tick_idx] = counts.get(clade, 0) / appearances[clade]\n",
    "\n",
    "for row in range(stacked.shape[0]):\n",
    "    stacked[row] = smooth(stacked[row], SMOOTH_WINDOW)\n",
    "\n",
    "cumulative = np.cumsum(stacked, axis=0)\n",
    "cum_with_zero = np.vstack([np.zeros((1, n_samples)), cumulative])\n",
    "\n",
    "other_raw = np.zeros(n_samples)\n",
    "for tick_idx, t in enumerate(sample_ticks):\n",
    "    total = sum(freq_raw[t].values())\n",
    "    tracked = sum(freq[t].get(c, 0) for c in relevant)\n",
    "    other_raw[tick_idx] = total - tracked\n",
    "other = smooth(other_raw, SMOOTH_WINDOW)\n",
    "\n",
    "# Depths for z-ordering (parents behind, children in front)\n",
    "clade_depths = {}\n",
    "for root in clade_roots:\n",
    "    clade_depths[root] = 0\n",
    "    for u, v in nx.bfs_edges(G_clade, root):\n",
    "        clade_depths[v] = clade_depths[u] + 1\n",
    "\n",
    "# --- 8. Colors (extended 40-color palette for high clade counts) ---\n",
    "PALETTE = [\n",
    "    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "    '#8c564b', '#e377c2', '#bcbd22', '#17becf', '#aec7e8',\n",
    "    '#ffbb78', '#98df8a', '#ff9896', '#c5b0d5', '#c49c94',\n",
    "    '#f7b6d2', '#dbdb8d', '#9edae5', '#393b79', '#637939',\n",
    "    '#e6550d', '#31a354', '#756bb1', '#636363', '#6baed6',\n",
    "    '#fd8d3c', '#74c476', '#9e9ac8', '#969696', '#9ecae1',\n",
    "    '#fdae6b', '#a1d99b', '#bcbddc', '#bdbdbd', '#c6dbef',\n",
    "    '#fdd0a2', '#c7e9c0', '#dadaeb', '#d9d9d9', '#deebf7',\n",
    "]\n",
    "\n",
    "clade_colors = {}\n",
    "sorted_clades = sorted(clade_set, key=lambda x: -clade_totals.get(x, 0))\n",
    "for i, c in enumerate(sorted_clades):\n",
    "    clade_colors[c] = PALETTE[i % len(PALETTE)]\n",
    "for c in relevant - clade_set:\n",
    "    clade_colors[c] = '#d4d4d8'\n",
    "\n",
    "# --- 9. Plot ---\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "\n",
    "# \"Other\" band on top\n",
    "total_tracked = cumulative[-1]\n",
    "ax.fill_between(tick_arr, total_tracked, total_tracked + other,\n",
    "                facecolor='#e8e8e8', edgecolor='#f0f0f0', linewidth=0.1)\n",
    "\n",
    "# Clade bands: parents first (behind), children in front\n",
    "for clade in sorted(set(tour), key=lambda g: clade_depths.get(g, 0)):\n",
    "    indices = [i for i, g in enumerate(tour) if g == clade]\n",
    "    bottom = cum_with_zero[indices[0]]\n",
    "    top = cumulative[indices[-1]]\n",
    "    ax.fill_between(tick_arr, bottom, top,\n",
    "                     facecolor=clade_colors.get(clade, '#aaaaaa'),\n",
    "                     edgecolor='white', linewidth=0.2)\n",
    "\n",
    "ax.set_xlabel('Tick', fontsize=13)\n",
    "ax.set_ylabel('Living Organisms', fontsize=13)\n",
    "ax.set_xlim(tick_arr[0], tick_arr[-1])\n",
    "ax.set_ylim(0, None)\n",
    "\n",
    "# Adaptive tick formatting\n",
    "tick_range = tick_arr[-1] - tick_arr[0]\n",
    "if tick_range >= 1e6:\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x/1e6:.0f}M'))\n",
    "elif tick_range >= 1e3:\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x/1e3:.0f}K'))\n",
    "\n",
    "# Legend: top clades + \"Other\"\n",
    "legend_clades = sorted_clades[:min(10, len(sorted_clades))]\n",
    "handles = [Patch(facecolor=clade_colors[c], label=f'Clade {format_genome_hash(c)}')\n",
    "           for c in legend_clades]\n",
    "handles.append(Patch(facecolor='#e8e8e8',\n",
    "                     label=f'Other ({len(tree_raw) - len(clade_set):,} genomes)'))\n",
    "ax.legend(handles=handles, loc='upper left', fontsize=9, framealpha=0.9)\n",
    "\n",
    "ax.set_title(\n",
    "    f'Muller Plot — Lineage Clade Dynamics\\n'\n",
    "    f'{len(clade_set)} clades (grouped at depth {best_depth}) '\n",
    "    f'from {len(tree_raw):,} genomes',\n",
    "    fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nTop clades by total organism-ticks:\")\n",
    "for i, c in enumerate(sorted_clades[:10]):\n",
    "    pct = 100 * clade_totals[c] / total_ot\n",
    "    print(f\"  {i+1}. {format_genome_hash(c):>6s}  {clade_totals[c]:6,} ({pct:4.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Working With Local Parquet Files\n",
    "\n",
    "When running your own simulations, you can skip the REST API entirely and point DuckDB directly at the Parquet files on disk. This is the most powerful pattern for large-scale analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What's Next\n",
    "\n",
    "This notebook demonstrates a subset of what you can extract from Evochora's data. Some directions to explore on your own:\n",
    "\n",
    "- **Survival analysis** — Sample organisms across multiple ticks to build Kaplan-Meier curves and measure lineage half-life.\n",
    "- **Fitness landscapes** — Combine phylogenetic depth with organism energy and reproduction rate to map the adaptive landscape.\n",
    "- **Custom metrics** — Write your own analytics plugin in Java. It gets access to every tick's state and exports results as Parquet automatically. See the [existing plugins](https://github.com/evochora/evochora/tree/main/src/main/java/org/evochora/datapipeline/services/analytics/plugins) for examples.\n",
    "- **Direct Parquet access** — For large-scale analysis, skip the API and point DuckDB directly at the Parquet files in your simulation's storage directory.\n",
    "\n",
    "For background on Evochora's design, see the [Scientific Overview](https://github.com/evochora/evochora/blob/main/docs/SCIENTIFIC_OVERVIEW.md) and the [Assembly Specification](https://github.com/evochora/evochora/blob/main/docs/ASSEMBLY_SPEC.md)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Evochora Data Analysis Guide",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
