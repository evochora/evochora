package org.evochora.datapipeline.api.analytics;

import java.util.List;

import org.evochora.datapipeline.api.contracts.TickData;

import com.typesafe.config.Config;

/**
 * Interface for Analytics Plugins.
 * <p>
 * Plugins define WHAT data to extract, while the indexer handles HOW to write it
 * (DuckDB, Parquet, LOD generation, storage). This separation keeps plugins simple
 * and focuses them on domain logic.
 * <p>
 * <strong>Minimal Plugin Implementation:</strong>
 * <pre>{@code
 * public class MyMetricsPlugin extends AbstractAnalyticsPlugin {
 *     @Override
 *     public ParquetSchema getSchema() {
 *         return ParquetSchema.builder()
 *             .column("tick", ColumnType.BIGINT)
 *             .column("value", ColumnType.DOUBLE)
 *             .build();
 *     }
 *
 *     @Override
 *     public List<Object[]> extractRows(TickData tick) {
 *         return List.of(new Object[] { tick.getTickNumber(), computeValue(tick) });
 *     }
 *
 *     @Override
 *     public ManifestEntry getManifestEntry() { ... }
 * }
 * }</pre>
 * <p>
 * Instances are created per-service, so they do NOT need to be thread-safe.
 */
public interface IAnalyticsPlugin {
    
    /**
     * Configure the plugin from HOCON.
     * <p>
     * Standard options read by AbstractAnalyticsPlugin:
     * <ul>
     *   <li>{@code metricId} - Unique identifier for the metric (required)</li>
     *   <li>{@code samplingInterval} - Process every Nth tick (default: 1)</li>
     * </ul>
     *
     * @param config The plugin-specific configuration object
     */
    void configure(Config config);

    /**
     * Initialize plugin for a specific run.
     * <p>
     * Called once per run (or per service start). Use for any per-run setup.
     *
     * @param context Provides access to metadata and run information
     */
    void initialize(IAnalyticsContext context);
    
    /**
     * Returns the Parquet schema for this plugin's output.
     * <p>
     * The indexer uses this schema to:
     * <ol>
     *   <li>Create the DuckDB table</li>
     *   <li>Bind values from {@link #extractRows(TickData)}</li>
     *   <li>Export to Parquet format</li>
     * </ol>
     * <p>
     * <strong>Important:</strong> The schema must match the row arrays returned by
     * {@link #extractRows(TickData)} in both column count and type order.
     *
     * @return The Parquet schema definition
     */
    ParquetSchema getSchema();
    
    /**
     * Extracts row data from a single tick.
     * <p>
     * The indexer calls this for each tick (after sampling), collects the rows,
     * and handles all I/O (DuckDB insertion, Parquet export, storage upload).
     * <p>
     * Each {@code Object[]} in the returned list represents one row. The array
     * elements must match the schema column types:
     * <ul>
     *   <li>{@link ColumnType#BIGINT} → {@code Long}</li>
     *   <li>{@link ColumnType#INTEGER} → {@code Integer}</li>
     *   <li>{@link ColumnType#DOUBLE} → {@code Double}</li>
     *   <li>{@link ColumnType#VARCHAR} → {@code String}</li>
     *   <li>{@link ColumnType#BOOLEAN} → {@code Boolean}</li>
     * </ul>
     * <p>
     * <strong>Multiple Rows:</strong> Return multiple rows if a single tick produces
     * multiple data points (e.g., per-species breakdown).
     * <p>
     * <strong>No Data:</strong> Return empty list if this tick should be skipped
     * (beyond normal sampling).
     *
     * @param tick The tick data to process
     * @return List of rows (each row is Object[] matching schema), or empty list
     */
    List<Object[]> extractRows(TickData tick);

    /**
     * Called when indexer shuts down or finishes a run.
     * <p>
     * Use for any cleanup. Note: The indexer handles Parquet flushing automatically.
     */
    void onFinish();

    /**
     * Returns the manifest entry describing the metric generated by this plugin.
     * <p>
     * The indexer writes this to {@code {metric_id}/metadata.json} (idempotently).
     * The manifest tells the frontend how to discover and visualize this metric.
     *
     * @return The manifest entry, or null if plugin produces no visible metric
     */
    ManifestEntry getManifestEntry();
    
    /**
     * Returns the unique metric identifier for this plugin.
     * <p>
     * Used by the indexer for:
     * <ul>
     *   <li>Storage paths: {@code {runId}/analytics/{metricId}/...}</li>
     *   <li>Logging and error messages</li>
     *   <li>Manifest aggregation</li>
     * </ul>
     *
     * @return The metric ID (e.g., "population", "energy", "spatial")
     */
    String getMetricId();
    
    /**
     * Returns the configured sampling interval.
     * <p>
     * The indexer uses this to skip ticks: only process every Nth tick.
     *
     * @return Sampling interval (1 = every tick, 10 = every 10th tick)
     */
    int getSamplingInterval();
    
    /**
     * Returns the LOD (Level of Detail) factor.
     * <p>
     * Each higher LOD level samples at {@code lodFactor^level} times the base interval.
     * Example with lodFactor=10 and samplingInterval=1:
     * <ul>
     *   <li>lod0: every tick (interval=1)</li>
     *   <li>lod1: every 10th tick (interval=10)</li>
     *   <li>lod2: every 100th tick (interval=100)</li>
     * </ul>
     *
     * @return LOD factor (default: 10)
     */
    int getLodFactor();
    
    /**
     * Returns the number of LOD levels to generate.
     * <p>
     * The indexer generates separate Parquet files for each LOD level:
     * <ul>
     *   <li>lodLevels=1: only lod0 (full resolution)</li>
     *   <li>lodLevels=2: lod0 + lod1 (10x downsampled)</li>
     *   <li>lodLevels=3: lod0 + lod1 + lod2 (100x downsampled)</li>
     * </ul>
     *
     * @return Number of LOD levels (default: 1)
     */
    int getLodLevels();
}
